## Lab 2.4 - Ceph Operational (Object Storage)

**Preparation**

Before you begin, log in using the `nusactl login` command with your ADINUSA credentials.

```
student@ceph1:~$ nusactl login
```

After login, run the `nusactl start cpadm-002-4` command. This command runs the start script and pre-configures your lab environment.

```
student@ceph1:~$ nusactl start cpadm-002-4
```

**Instructions**

**Execute on pod-username-ceph1**

1. **Create Realm and Zone:**

   ```bash
   su - ceph-adm

   # Create a realm
   sudo radosgw-admin realm create --rgw-realm=myorg --default

   # Create a zone group
   sudo radosgw-admin zonegroup create --rgw-zonegroup=jkt  --master --default

   # Create a zone
   sudo radosgw-admin zone create --rgw-zonegroup=jkt --rgw-zone=id-jkt-1 --master --default

   # Commit the realm configuration
   sudo radosgw-admin period update --rgw-realm=myorg --commit
   ```

2. **Create RadosGW Instance:**

   ```bash
   # Deploy a RadosGW instance on pod--ceph1
   sudo ceph orch apply rgw jkt --realm=myorg --zone=id-jkt-1 --port=8080 --placement="1 pod--ceph1"

   # Monitor the deployment status
   sudo watch "ceph orch ls | grep jkt"
   ```

3. **Install AWS CLI:**

   ```bash
   sudo apt install -y awscli
   ```

4. **Create a User:**

   ```bash
   # List existing users
   sudo radosgw-admin user list

   # Create a new user
   sudo radosgw-admin user create --uid=user0 --display-name=user0
   ```

   **Note:** Save the access key and secret key from the output.

5. **Configure AWS CLI:**

   ```bash
   sudo aws configure --profile=user0
   ```

   Enter the access key ID, secret access key, default region (id-jkt-1), and default output format (json).

6. **Create Buckets:**

   ```bash
   # Create buckets
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3api create-bucket --bucket bucket0
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3api create-bucket --bucket bucket1
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3api create-bucket --bucket bucket2

   # List buckets
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 ls
   ```

7. **Upload Objects:**

   ```bash
   # Create files
   echo "file0" > file0.txt
   echo "file1" > file1.txt
   echo "file2" > file2.txt

   # Upload files to buckets
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 cp file0.txt s3://bucket0
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 cp file1.txt s3://bucket1
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 cp file2.txt s3://bucket2

   # List objects in buckets
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 ls s3://bucket0
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 ls s3://bucket1
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 ls s3://bucket2
   ```

8. **Delete Files:**

   ```bash
   rm file0.txt file1.txt file2.txt
   ```

9. **Download Objects:**

   ```bash
   # Download objects from buckets
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 cp s3://bucket0/file0.txt .
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 cp s3://bucket1/file1.txt .
   sudo aws --profile user0 --endpoint-url http://pod--ceph1:8080/ s3 cp s3://bucket2/file2.txt .

   # List downloaded files
   ls file*
   ```
